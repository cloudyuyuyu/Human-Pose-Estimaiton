input: "data"
input_dim: 1
input_dim: 4
input_dim: 368
input_dim: 368
layer {
  name: "image"
  type: "Slice"
  bottom: "data"
  top: "image"
  top: "center_map"
  slice_param {
    slice_point: 3
    axis: 1
  }
}
layer {
  name: "pool_center_lower"
  type: "Pooling"
  bottom: "center_map"
  top: "pool_center_lower"
  pooling_param {
    pool: AVE
    kernel_size: 9
    stride: 8
  }
}


#######################################
#-----------get local feature----------
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "Convolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "Convolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "Convolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "Convolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "Convolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "Convolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "Convolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}

layer {
  name: "local_feat"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "conv4_4_CPM"
  param {
    lr_mult: 1.0
    decay_mult: 1
  }
  param {
    lr_mult: 2.0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "local_feat_relu"
  type: "ReLU"
  bottom: "conv4_4_CPM"
  top: "conv4_4_CPM"
}

#------------------------------use this feature----------------------------------
#################################################################################
#------------------------------stage 1-------------------------------------------
layer {
  name: "conv1_block1_stage1"
  type: "Convolution"
  bottom: "conv4_4_CPM"
  top: "conv1_block1_stage1"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block1_stage1"
  type: "ReLU"
  bottom: "conv1_block1_stage1"
  top: "conv1_block1_stage1"
}

layer {
  name: "conv2_block1_stage1"
  type: "Convolution"
  bottom: "conv1_block1_stage1"
  top: "conv2_block1_stage1"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block1_stage1"
  type: "ReLU"
  bottom: "conv2_block1_stage1"
  top: "conv2_block1_stage1"
}

layer {
  name: "conv3_block1_stage1"
  type: "Convolution"
  bottom: "conv2_block1_stage1"
  top: "conv3_block1_stage1"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block1_stage1"
  type: "ReLU"
  bottom: "conv3_block1_stage1"
  top: "conv3_block1_stage1"
}

layer {
  name: "concat_block1_stage1"
  type: "Concat"
  bottom: "conv1_block1_stage1"
  bottom: "conv2_block1_stage1"
  bottom: "conv3_block1_stage1"
  top: "concat_block1_stage1"
  concat_param {
    axis: 1
  }
}

layer {
  name: "conv6_stage1"
  type: "Convolution"
  bottom: "concat_block1_stage1"
  top: "conv6_stage1"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6_stage1"
  type: "ReLU"
  bottom: "conv6_stage1"
  top: "conv6_stage1"
}

layer {
  name: "conv7_stage1"
  type: "Convolution"
  bottom: "conv6_stage1"
  top: "conv7_stage1"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 15
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}


#################################################################################
#--------------------------stage 2-----------------------------------------------
layer {
  name: "concat_stage2"
  type: "Concat"
  bottom: "conv4_4_CPM"
  bottom: "conv7_stage1"
  bottom: "pool_center_lower"
  top: "concat_stage2"
  concat_param {
    axis: 1
  }
}

layer {
  name: "conv_stage2"
  type: "Convolution"
  bottom: "concat_stage2"
  top: "conv_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_stage2"
  type: "ReLU"
  bottom: "conv_stage2"
  top: "conv_stage2"
}

#------------------block1----------------------
layer {
  name: "conv1_block1_stage2"
  type: "Convolution"
  bottom: "conv_stage2"
  top: "conv1_block1_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block1_stage2"
  type: "ReLU"
  bottom: "conv1_block1_stage2"
  top: "conv1_block1_stage2"
}

layer {
  name: "conv2_block1_stage2"
  type: "Convolution"
  bottom: "conv1_block1_stage2"
  top: "conv2_block1_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block1_stage2"
  type: "ReLU"
  bottom: "conv2_block1_stage2"
  top: "conv2_block1_stage2"
}

layer {
  name: "conv3_block1_stage2"
  type: "Convolution"
  bottom: "conv2_block1_stage2"
  top: "conv3_block1_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block1_stage2"
  type: "ReLU"
  bottom: "conv3_block1_stage2"
  top: "conv3_block1_stage2"
}

layer {
  name: "concat_block1_stage2"
  type: "Concat"
  bottom: "conv1_block1_stage2"
  bottom: "conv2_block1_stage2"
  bottom: "conv3_block1_stage2"
  top: "concat_block1_stage2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bypass_block1_stage2"
  type: "Eltwise"
  bottom: "conv_stage2"
  bottom: "concat_block1_stage2"
  top: "block1_EltAdd_stage2"
}

#--------------block2----------------------------------
layer {
  name: "conv1_block2_stage2"
  type: "Convolution"
  bottom: "block1_EltAdd_stage2"
  top: "conv1_block2_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block2_stage2"
  type: "ReLU"
  bottom: "conv1_block2_stage2"
  top: "conv1_block2_stage2"
}

layer {
  name: "conv2_block2_stage2"
  type: "Convolution"
  bottom: "conv1_block2_stage2"
  top: "conv2_block2_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
    type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block2_stage2"
  type: "ReLU"
  bottom: "conv2_block2_stage2"
  top: "conv2_block2_stage2"
}

layer {
  name: "conv3_block2_stage2"
  type: "Convolution"
  bottom: "conv2_block2_stage2"
  top: "conv3_block2_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block2_stage2"
  type: "ReLU"
  bottom: "conv3_block2_stage2"
  top: "conv3_block2_stage2"
}

layer {
  name: "concat_block2_stage2"
  type: "Concat"
  bottom: "conv1_block2_stage2"
  bottom: "conv2_block2_stage2"
  bottom: "conv3_block2_stage2"
  top: "concat_block2_stage2"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block2_stage2"
  type: "Eltwise"
  bottom: "block1_EltAdd_stage2"
  bottom: "concat_block2_stage2"
  top: "block2_EltAdd_stage2"
}

#-------------------block3--------------------
layer {
  name: "conv1_block3_stage2"
  type: "Convolution"
  bottom: "block2_EltAdd_stage2"
  top: "conv1_block3_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block3_stage2"
  type: "ReLU"
  bottom: "conv1_block3_stage2"
  top: "conv1_block3_stage2"
}

layer {
  name: "conv2_block3_stage2"
  type: "Convolution"
  bottom: "conv1_block3_stage2"
  top: "conv2_block3_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block3_stage2"
  type: "ReLU"
  bottom: "conv2_block3_stage2"
  top: "conv2_block3_stage2"
}

layer {
  name: "conv3_block3_stage2"
  type: "Convolution"
  bottom: "conv2_block3_stage2"
  top: "conv3_block3_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block3_stage2"
  type: "ReLU"
  bottom: "conv3_block3_stage2"
  top: "conv3_block3_stage2"
}

layer {
  name: "concat_block3_stage2"
  type: "Concat"
  bottom: "conv1_block3_stage2"
  bottom: "conv2_block3_stage2"
  bottom: "conv3_block3_stage2"
  top: "concat_block3_stage2"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block3_stage2"
  type: "Eltwise"
  bottom: "block2_EltAdd_stage2"
  bottom: "concat_block3_stage2"
  top: "block3_EltAdd_stage2"
}

#---------------------block4----------------------------
layer {
  name: "conv1_block4_stage2"
  type: "Convolution"
  bottom: "block3_EltAdd_stage2"
  top: "conv1_block4_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
   
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block4_stage2"
  type: "ReLU"
  bottom: "conv1_block4_stage2"
  top: "conv1_block4_stage2"
}

layer {
  name: "conv2_block4_stage2"
  type: "Convolution"
  bottom: "conv1_block4_stage2"
  top: "conv2_block4_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block4_stage2"
  type: "ReLU"
  bottom: "conv2_block4_stage2"
  top: "conv2_block4_stage2"
}

layer {
  name: "conv3_block4_stage2"
  type: "Convolution"
  bottom: "conv2_block4_stage2"
  top: "conv3_block4_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block4_stage2"
  type: "ReLU"
  bottom: "conv3_block4_stage2"
  top: "conv3_block4_stage2"
}

layer {
  name: "concat_block4_stage2"
  type: "Concat"
  bottom: "conv1_block4_stage2"
  bottom: "conv2_block4_stage2"
  bottom: "conv3_block4_stage2"
  top: "concat_block4_stage2"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block4_stage2"
  type: "Eltwise"
  bottom: "block3_EltAdd_stage2"
  bottom: "concat_block4_stage2"
  top: "block4_EltAdd_stage2"
}

#----------------------block5------------------

layer {
  name: "conv1_block5_stage2"
  type: "Convolution"
  bottom: "block4_EltAdd_stage2"
  top: "conv1_block5_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block5_stage2"
  type: "ReLU"
  bottom: "conv1_block5_stage2"
  top: "conv1_block5_stage2"
}

layer {
  name: "conv2_block5_stage2"
  type: "Convolution"
  bottom: "conv1_block5_stage2"
  top: "conv2_block5_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block5_stage2"
  type: "ReLU"
  bottom: "conv2_block5_stage2"
  top: "conv2_block5_stage2"
}

layer {
  name: "conv3_block5_stage2"
  type: "Convolution"
  bottom: "conv2_block5_stage2"
  top: "conv3_block5_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block5_stage2"
  type: "ReLU"
  bottom: "conv3_block5_stage2"
  top: "conv3_block5_stage2"
}

layer {
  name: "concat_block5_stage2"
  type: "Concat"
  bottom: "conv1_block5_stage2"
  bottom: "conv2_block5_stage2"
  bottom: "conv3_block5_stage2"
  top: "concat_block5_stage2"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block5_stage2"
  type: "Eltwise"
  bottom: "block4_EltAdd_stage2"
  bottom: "concat_block5_stage2"
  top: "block5_EltAdd_stage2"
}

layer {
  name: "conv1_stage2"
  type: "Convolution"
  bottom: "block5_EltAdd_stage2"
  top: "conv1_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_stage2"
  type: "ReLU"
  bottom: "conv1_stage2"
  top: "conv1_stage2"
}

layer {
  name: "conv2_stage2"
  type: "Convolution"
  bottom: "conv1_stage2"
  top: "conv2_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 15
    pad: 0
    kernel_size: 1
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}



#################################################################################
#--------------------------stage 3-----------------------------------------------
layer {
  name: "concat_stage3"
  type: "Concat"
  bottom: "conv4_4_CPM"
  bottom: "conv2_stage2"
  bottom: "pool_center_lower"
  top: "concat_stage3"
  concat_param {
    axis: 1
  }
}

layer {
  name: "conv_stage3"
  type: "Convolution"
  bottom: "concat_stage3"
  top: "conv_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_stage3"
  type: "ReLU"
  bottom: "conv_stage3"
  top: "conv_stage3"
}

#------------------block1----------------------
layer {
  name: "conv1_block1_stage3"
  type: "Convolution"
  bottom: "conv_stage3"
  top: "conv1_block1_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block1_stage3"
  type: "ReLU"
  bottom: "conv1_block1_stage3"
  top: "conv1_block1_stage3"
}

layer {
  name: "conv2_block1_stage3"
  type: "Convolution"
  bottom: "conv1_block1_stage3"
  top: "conv2_block1_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block1_stage3"
  type: "ReLU"
  bottom: "conv2_block1_stage3"
  top: "conv2_block1_stage3"
}

layer {
  name: "conv3_block1_stage3"
  type: "Convolution"
  bottom: "conv2_block1_stage3"
  top: "conv3_block1_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block1_stage3"
  type: "ReLU"
  bottom: "conv3_block1_stage3"
  top: "conv3_block1_stage3"
}

layer {
  name: "concat_block1_stage3"
  type: "Concat"
  bottom: "conv1_block1_stage3"
  bottom: "conv2_block1_stage3"
  bottom: "conv3_block1_stage3"
  top: "concat_block1_stage3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bypass_block1_stage3"
  type: "Eltwise"
  bottom: "conv_stage3"
  bottom: "concat_block1_stage3"
  top: "block1_EltAdd_stage3"
}

#--------------block2----------------------------------
layer {
  name: "conv1_block2_stage3"
  type: "Convolution"
  bottom: "block1_EltAdd_stage3"
  top: "conv1_block2_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block2_stage3"
  type: "ReLU"
  bottom: "conv1_block2_stage3"
  top: "conv1_block2_stage3"
}

layer {
  name: "conv2_block2_stage3"
  type: "Convolution"
  bottom: "conv1_block2_stage3"
  top: "conv2_block2_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block2_stage3"
  type: "ReLU"
  bottom: "conv2_block2_stage3"
  top: "conv2_block2_stage3"
}

layer {
  name: "conv3_block2_stage3"
  type: "Convolution"
  bottom: "conv2_block2_stage3"
  top: "conv3_block2_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block2_stage3"
  type: "ReLU"
  bottom: "conv3_block2_stage3"
  top: "conv3_block2_stage3"
}

layer {
  name: "concat_block2_stage3"
  type: "Concat"
  bottom: "conv1_block2_stage3"
  bottom: "conv2_block2_stage3"
  bottom: "conv3_block2_stage3"
  top: "concat_block2_stage3"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block2_stage3"
  type: "Eltwise"
  bottom: "block1_EltAdd_stage3"
  bottom: "concat_block2_stage3"
  top: "block2_EltAdd_stage3"
}

#-------------------block3--------------------
layer {
  name: "conv1_block3_stage3"
  type: "Convolution"
  bottom: "block2_EltAdd_stage3"
  top: "conv1_block3_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block3_stage3"
  type: "ReLU"
  bottom: "conv1_block3_stage3"
  top: "conv1_block3_stage3"
}

layer {
  name: "conv2_block3_stage3"
  type: "Convolution"
  bottom: "conv1_block3_stage3"
  top: "conv2_block3_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block3_stage3"
  type: "ReLU"
  bottom: "conv2_block3_stage3"
  top: "conv2_block3_stage3"
}

layer {
  name: "conv3_block3_stage3"
  type: "Convolution"
  bottom: "conv2_block3_stage3"
  top: "conv3_block3_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block3_stage3"
  type: "ReLU"
  bottom: "conv3_block3_stage3"
  top: "conv3_block3_stage3"
}

layer {
  name: "concat_block3_stage3"
  type: "Concat"
  bottom: "conv1_block3_stage3"
  bottom: "conv2_block3_stage3"
  bottom: "conv3_block3_stage3"
  top: "concat_block3_stage3"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block3_stage3"
  type: "Eltwise"
  bottom: "block2_EltAdd_stage3"
  bottom: "concat_block3_stage3"
  top: "block3_EltAdd_stage3"
}

#---------------------block4----------------------------
layer {
  name: "conv1_block4_stage3"
  type: "Convolution"
  bottom: "block3_EltAdd_stage3"
  top: "conv1_block4_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block4_stage3"
  type: "ReLU"
  bottom: "conv1_block4_stage3"
  top: "conv1_block4_stage3"
}

layer {
  name: "conv2_block4_stage3"
  type: "Convolution"
  bottom: "conv1_block4_stage3"
  top: "conv2_block4_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block4_stage3"
  type: "ReLU"
  bottom: "conv2_block4_stage3"
  top: "conv2_block4_stage3"
}

layer {
  name: "conv3_block4_stage3"
  type: "Convolution"
  bottom: "conv2_block4_stage3"
  top: "conv3_block4_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block4_stage3"
  type: "ReLU"
  bottom: "conv3_block4_stage3"
  top: "conv3_block4_stage3"
}

layer {
  name: "concat_block4_stage3"
  type: "Concat"
  bottom: "conv1_block4_stage3"
  bottom: "conv2_block4_stage3"
  bottom: "conv3_block4_stage3"
  top: "concat_block4_stage3"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block4_stage3"
  type: "Eltwise"
  bottom: "block3_EltAdd_stage3"
  bottom: "concat_block4_stage3"
  top: "block4_EltAdd_stage3"
}

#----------------------block5------------------

layer {
  name: "conv1_block5_stage3"
  type: "Convolution"
  bottom: "block4_EltAdd_stage3"
  top: "conv1_block5_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block5_stage3"
  type: "ReLU"
  bottom: "conv1_block5_stage3"
  top: "conv1_block5_stage3"
}

layer {
  name: "conv2_block5_stage3"
  type: "Convolution"
  bottom: "conv1_block5_stage3"
  top: "conv2_block5_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block5_stage3"
  type: "ReLU"
  bottom: "conv2_block5_stage3"
  top: "conv2_block5_stage3"
}

layer {
  name: "conv3_block5_stage3"
  type: "Convolution"
  bottom: "conv2_block5_stage3"
  top: "conv3_block5_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block5_stage3"
  type: "ReLU"
  bottom: "conv3_block5_stage3"
  top: "conv3_block5_stage3"
}

layer {
  name: "concat_block5_stage3"
  type: "Concat"
  bottom: "conv1_block5_stage3"
  bottom: "conv2_block5_stage3"
  bottom: "conv3_block5_stage3"
  top: "concat_block5_stage3"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block5_stage3"
  type: "Eltwise"
  bottom: "block4_EltAdd_stage3"
  bottom: "concat_block5_stage3"
  top: "block5_EltAdd_stage3"
}

layer {
  name: "conv1_stage3"
  type: "Convolution"
  bottom: "block5_EltAdd_stage3"
  top: "conv1_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_stage3"
  type: "ReLU"
  bottom: "conv1_stage3"
  top: "conv1_stage3"
}

layer {
  name: "conv2_stage3"
  type: "Convolution"
  bottom: "conv1_stage3"
  top: "conv2_stage3"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 15
    pad: 0
    kernel_size: 1
    weight_filler {
     type: "gaussian"
     std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

#################################################################################
#--------------------------stage 4-----------------------------------------------
layer {
  name: "concat_stage4"
  type: "Concat"
  bottom: "conv4_4_CPM"
  bottom: "conv2_stage3"
  bottom: "pool_center_lower"
  top: "concat_stage4"
  concat_param {
    axis: 1
  }
}

layer {
  name: "conv_stage4"
  type: "Convolution"
  bottom: "concat_stage4"
  top: "conv_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_stage4"
  type: "ReLU"
  bottom: "conv_stage4"
  top: "conv_stage4"
}

#------------------block1----------------------
layer {
  name: "conv1_block1_stage4"
  type: "Convolution"
  bottom: "conv_stage4"
  top: "conv1_block1_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block1_stage4"
  type: "ReLU"
  bottom: "conv1_block1_stage4"
  top: "conv1_block1_stage4"
}

layer {
  name: "conv2_block1_stage4"
  type: "Convolution"
  bottom: "conv1_block1_stage4"
  top: "conv2_block1_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block1_stage4"
  type: "ReLU"
  bottom: "conv2_block1_stage4"
  top: "conv2_block1_stage4"
}

layer {
  name: "conv3_block1_stage4"
  type: "Convolution"
  bottom: "conv2_block1_stage4"
  top: "conv3_block1_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block1_stage4"
  type: "ReLU"
  bottom: "conv3_block1_stage4"
  top: "conv3_block1_stage4"
}

layer {
  name: "concat_block1_stage4"
  type: "Concat"
  bottom: "conv1_block1_stage4"
  bottom: "conv2_block1_stage4"
  bottom: "conv3_block1_stage4"
  top: "concat_block1_stage4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bypass_block1_stage4"
  type: "Eltwise"
  bottom: "conv_stage4"
  bottom: "concat_block1_stage4"
  top: "block1_EltAdd_stage4"
}

#--------------block2----------------------------------
layer {
  name: "conv1_block2_stage4"
  type: "Convolution"
  bottom: "block1_EltAdd_stage4"
  top: "conv1_block2_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block2_stage4"
  type: "ReLU"
  bottom: "conv1_block2_stage4"
  top: "conv1_block2_stage4"
}

layer {
  name: "conv2_block2_stage4"
  type: "Convolution"
  bottom: "conv1_block2_stage4"
  top: "conv2_block2_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block2_stage4"
  type: "ReLU"
  bottom: "conv2_block2_stage4"
  top: "conv2_block2_stage4"
}

layer {
  name: "conv3_block2_stage4"
  type: "Convolution"
  bottom: "conv2_block2_stage4"
  top: "conv3_block2_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block2_stage4"
  type: "ReLU"
  bottom: "conv3_block2_stage4"
  top: "conv3_block2_stage4"
}

layer {
  name: "concat_block2_stage4"
  type: "Concat"
  bottom: "conv1_block2_stage4"
  bottom: "conv2_block2_stage4"
  bottom: "conv3_block2_stage4"
  top: "concat_block2_stage4"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block2_stage4"
  type: "Eltwise"
  bottom: "block1_EltAdd_stage4"
  bottom: "concat_block2_stage4"
  top: "block2_EltAdd_stage4"
}

#-------------------block3--------------------
layer {
  name: "conv1_block3_stage4"
  type: "Convolution"
  bottom: "block2_EltAdd_stage4"
  top: "conv1_block3_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block3_stage4"
  type: "ReLU"
  bottom: "conv1_block3_stage4"
  top: "conv1_block3_stage4"
}

layer {
  name: "conv2_block3_stage4"
  type: "Convolution"
  bottom: "conv1_block3_stage4"
  top: "conv2_block3_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block3_stage4"
  type: "ReLU"
  bottom: "conv2_block3_stage4"
  top: "conv2_block3_stage4"
}

layer {
  name: "conv3_block3_stage4"
  type: "Convolution"
  bottom: "conv2_block3_stage4"
  top: "conv3_block3_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block3_stage4"
  type: "ReLU"
  bottom: "conv3_block3_stage4"
  top: "conv3_block3_stage4"
}

layer {
  name: "concat_block3_stage4"
  type: "Concat"
  bottom: "conv1_block3_stage4"
  bottom: "conv2_block3_stage4"
  bottom: "conv3_block3_stage4"
  top: "concat_block3_stage4"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block3_stage4"
  type: "Eltwise"
  bottom: "block2_EltAdd_stage4"
  bottom: "concat_block3_stage4"
  top: "block3_EltAdd_stage4"
}

#---------------------block4----------------------------
layer {
  name: "conv1_block4_stage4"
  type: "Convolution"
  bottom: "block3_EltAdd_stage4"
  top: "conv1_block4_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block4_stage4"
  type: "ReLU"
  bottom: "conv1_block4_stage4"
  top: "conv1_block4_stage4"
}

layer {
  name: "conv2_block4_stage4"
  type: "Convolution"
  bottom: "conv1_block4_stage4"
  top: "conv2_block4_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block4_stage4"
  type: "ReLU"
  bottom: "conv2_block4_stage4"
  top: "conv2_block4_stage4"
}

layer {
  name: "conv3_block4_stage4"
  type: "Convolution"
  bottom: "conv2_block4_stage4"
  top: "conv3_block4_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block4_stage4"
  type: "ReLU"
  bottom: "conv3_block4_stage4"
  top: "conv3_block4_stage4"
}

layer {
  name: "concat_block4_stage4"
  type: "Concat"
  bottom: "conv1_block4_stage4"
  bottom: "conv2_block4_stage4"
  bottom: "conv3_block4_stage4"
  top: "concat_block4_stage4"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block4_stage4"
  type: "Eltwise"
  bottom: "block3_EltAdd_stage4"
  bottom: "concat_block4_stage4"
  top: "block4_EltAdd_stage4"
}

#----------------------block5------------------

layer {
  name: "conv1_block5_stage4"
  type: "Convolution"
  bottom: "block4_EltAdd_stage4"
  top: "conv1_block5_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block5_stage4"
  type: "ReLU"
  bottom: "conv1_block5_stage4"
  top: "conv1_block5_stage4"
}

layer {
  name: "conv2_block5_stage4"
  type: "Convolution"
  bottom: "conv1_block5_stage4"
  top: "conv2_block5_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block5_stage4"
  type: "ReLU"
  bottom: "conv2_block5_stage4"
  top: "conv2_block5_stage4"
}

layer {
  name: "conv3_block5_stage4"
  type: "Convolution"
  bottom: "conv2_block5_stage4"
  top: "conv3_block5_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block5_stage4"
  type: "ReLU"
  bottom: "conv3_block5_stage4"
  top: "conv3_block5_stage4"
}

layer {
  name: "concat_block5_stage4"
  type: "Concat"
  bottom: "conv1_block5_stage4"
  bottom: "conv2_block5_stage4"
  bottom: "conv3_block5_stage4"
  top: "concat_block5_stage4"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block5_stage4"
  type: "Eltwise"
  bottom: "block4_EltAdd_stage4"
  bottom: "concat_block5_stage4"
  top: "block5_EltAdd_stage4"
}

layer {
  name: "conv1_stage4"
  type: "Convolution"
  bottom: "block5_EltAdd_stage4"
  top: "conv1_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_stage4"
  type: "ReLU"
  bottom: "conv1_stage4"
  top: "conv1_stage4"
}

layer {
  name: "conv2_stage4"
  type: "Convolution"
  bottom: "conv1_stage4"
  top: "conv2_stage4"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 15
    pad: 0
    kernel_size: 1
    weight_filler {
     type: "gaussian"
     std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

#################################################################################
#--------------------------stage 5-----------------------------------------------
layer {
  name: "concat_stage5"
  type: "Concat"
  bottom: "conv4_4_CPM"
  bottom: "conv2_stage4"
  bottom: "pool_center_lower"
  top: "concat_stage5"
  concat_param {
    axis: 1
  }
}

layer {
  name: "conv_stage5"
  type: "Convolution"
  bottom: "concat_stage5"
  top: "conv_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_stage5"
  type: "ReLU"
  bottom: "conv_stage5"
  top: "conv_stage5"
}

#------------------block1----------------------
layer {
  name: "conv1_block1_stage5"
  type: "Convolution"
  bottom: "conv_stage5"
  top: "conv1_block1_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block1_stage5"
  type: "ReLU"
  bottom: "conv1_block1_stage5"
  top: "conv1_block1_stage5"
}

layer {
  name: "conv2_block1_stage5"
  type: "Convolution"
  bottom: "conv1_block1_stage5"
  top: "conv2_block1_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block1_stage5"
  type: "ReLU"
  bottom: "conv2_block1_stage5"
  top: "conv2_block1_stage5"
}

layer {
  name: "conv3_block1_stage5"
  type: "Convolution"
  bottom: "conv2_block1_stage5"
  top: "conv3_block1_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block1_stage5"
  type: "ReLU"
  bottom: "conv3_block1_stage5"
  top: "conv3_block1_stage5"
}

layer {
  name: "concat_block1_stage5"
  type: "Concat"
  bottom: "conv1_block1_stage5"
  bottom: "conv2_block1_stage5"
  bottom: "conv3_block1_stage5"
  top: "concat_block1_stage5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bypass_block1_stage5"
  type: "Eltwise"
  bottom: "conv_stage5"
  bottom: "concat_block1_stage5"
  top: "block1_EltAdd_stage5"
}

#--------------block2----------------------------------
layer {
  name: "conv1_block2_stage5"
  type: "Convolution"
  bottom: "block1_EltAdd_stage5"
  top: "conv1_block2_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block2_stage5"
  type: "ReLU"
  bottom: "conv1_block2_stage5"
  top: "conv1_block2_stage5"
}

layer {
  name: "conv2_block2_stage5"
  type: "Convolution"
  bottom: "conv1_block2_stage5"
  top: "conv2_block2_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block2_stage5"
  type: "ReLU"
  bottom: "conv2_block2_stage5"
  top: "conv2_block2_stage5"
}

layer {
  name: "conv3_block2_stage5"
  type: "Convolution"
  bottom: "conv2_block2_stage5"
  top: "conv3_block2_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block2_stage5"
  type: "ReLU"
  bottom: "conv3_block2_stage5"
  top: "conv3_block2_stage5"
}

layer {
  name: "concat_block2_stage5"
  type: "Concat"
  bottom: "conv1_block2_stage5"
  bottom: "conv2_block2_stage5"
  bottom: "conv3_block2_stage5"
  top: "concat_block2_stage5"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block2_stage5"
  type: "Eltwise"
  bottom: "block1_EltAdd_stage5"
  bottom: "concat_block2_stage5"
  top: "block2_EltAdd_stage5"
}

#-------------------block3--------------------
layer {
  name: "conv1_block3_stage5"
  type: "Convolution"
  bottom: "block2_EltAdd_stage5"
  top: "conv1_block3_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block3_stage5"
  type: "ReLU"
  bottom: "conv1_block3_stage5"
  top: "conv1_block3_stage5"
}

layer {
  name: "conv2_block3_stage5"
  type: "Convolution"
  bottom: "conv1_block3_stage5"
  top: "conv2_block3_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block3_stage5"
  type: "ReLU"
  bottom: "conv2_block3_stage5"
  top: "conv2_block3_stage5"
}

layer {
  name: "conv3_block3_stage5"
  type: "Convolution"
  bottom: "conv2_block3_stage5"
  top: "conv3_block3_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block3_stage5"
  type: "ReLU"
  bottom: "conv3_block3_stage5"
  top: "conv3_block3_stage5"
}

layer {
  name: "concat_block3_stage5"
  type: "Concat"
  bottom: "conv1_block3_stage5"
  bottom: "conv2_block3_stage5"
  bottom: "conv3_block3_stage5"
  top: "concat_block3_stage5"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block3_stage5"
  type: "Eltwise"
  bottom: "block2_EltAdd_stage5"
  bottom: "concat_block3_stage5"
  top: "block3_EltAdd_stage5"
}

#---------------------block4----------------------------
layer {
  name: "conv1_block4_stage5"
  type: "Convolution"
  bottom: "block3_EltAdd_stage5"
  top: "conv1_block4_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block4_stage5"
  type: "ReLU"
  bottom: "conv1_block4_stage5"
  top: "conv1_block4_stage5"
}

layer {
  name: "conv2_block4_stage5"
  type: "Convolution"
  bottom: "conv1_block4_stage5"
  top: "conv2_block4_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block4_stage5"
  type: "ReLU"
  bottom: "conv2_block4_stage5"
  top: "conv2_block4_stage5"
}

layer {
  name: "conv3_block4_stage5"
  type: "Convolution"
  bottom: "conv2_block4_stage5"
  top: "conv3_block4_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block4_stage5"
  type: "ReLU"
  bottom: "conv3_block4_stage5"
  top: "conv3_block4_stage5"
}

layer {
  name: "concat_block4_stage5"
  type: "Concat"
  bottom: "conv1_block4_stage5"
  bottom: "conv2_block4_stage5"
  bottom: "conv3_block4_stage5"
  top: "concat_block4_stage5"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block4_stage5"
  type: "Eltwise"
  bottom: "block3_EltAdd_stage5"
  bottom: "concat_block4_stage5"
  top: "block4_EltAdd_stage5"
}

#----------------------block5------------------

layer {
  name: "conv1_block5_stage5"
  type: "Convolution"
  bottom: "block4_EltAdd_stage5"
  top: "conv1_block5_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block5_stage5"
  type: "ReLU"
  bottom: "conv1_block5_stage5"
  top: "conv1_block5_stage5"
}

layer {
  name: "conv2_block5_stage5"
  type: "Convolution"
  bottom: "conv1_block5_stage5"
  top: "conv2_block5_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block5_stage5"
  type: "ReLU"
  bottom: "conv2_block5_stage5"
  top: "conv2_block5_stage5"
}

layer {
  name: "conv3_block5_stage5"
  type: "Convolution"
  bottom: "conv2_block5_stage5"
  top: "conv3_block5_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block5_stage5"
  type: "ReLU"
  bottom: "conv3_block5_stage5"
  top: "conv3_block5_stage5"
}

layer {
  name: "concat_block5_stage5"
  type: "Concat"
  bottom: "conv1_block5_stage5"
  bottom: "conv2_block5_stage5"
  bottom: "conv3_block5_stage5"
  top: "concat_block5_stage5"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block5_stage5"
  type: "Eltwise"
  bottom: "block4_EltAdd_stage5"
  bottom: "concat_block5_stage5"
  top: "block5_EltAdd_stage5"
}

layer {
  name: "conv1_stage5"
  type: "Convolution"
  bottom: "block5_EltAdd_stage5"
  top: "conv1_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_stage5"
  type: "ReLU"
  bottom: "conv1_stage5"
  top: "conv1_stage5"
}

layer {
  name: "conv2_stage5"
  type: "Convolution"
  bottom: "conv1_stage5"
  top: "conv2_stage5"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 15
    pad: 0
    kernel_size: 1
    weight_filler {
     type: "gaussian"
     std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}


#################################################################################
#--------------------------stage 6-----------------------------------------------
layer {
  name: "concat_stage6"
  type: "Concat"
  bottom: "conv4_4_CPM"
  bottom: "conv2_stage5"
  bottom: "pool_center_lower"
  top: "concat_stage6"
  concat_param {
    axis: 1
  }
}

layer {
  name: "conv_stage6"
  type: "Convolution"
  bottom: "concat_stage6"
  top: "conv_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_stage6"
  type: "ReLU"
  bottom: "conv_stage6"
  top: "conv_stage6"
}

#------------------block1----------------------
layer {
  name: "conv1_block1_stage6"
  type: "Convolution"
  bottom: "conv_stage6"
  top: "conv1_block1_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block1_stage6"
  type: "ReLU"
  bottom: "conv1_block1_stage6"
  top: "conv1_block1_stage6"
}

layer {
  name: "conv2_block1_stage6"
  type: "Convolution"
  bottom: "conv1_block1_stage6"
  top: "conv2_block1_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block1_stage6"
  type: "ReLU"
  bottom: "conv2_block1_stage6"
  top: "conv2_block1_stage6"
}

layer {
  name: "conv3_block1_stage6"
  type: "Convolution"
  bottom: "conv2_block1_stage6"
  top: "conv3_block1_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block1_stage6"
  type: "ReLU"
  bottom: "conv3_block1_stage6"
  top: "conv3_block1_stage6"
}

layer {
  name: "concat_block1_stage6"
  type: "Concat"
  bottom: "conv1_block1_stage6"
  bottom: "conv2_block1_stage6"
  bottom: "conv3_block1_stage6"
  top: "concat_block1_stage6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "bypass_block1_stage6"
  type: "Eltwise"
  bottom: "conv_stage6"
  bottom: "concat_block1_stage6"
  top: "block1_EltAdd_stage6"
}

#--------------block2----------------------------------
layer {
  name: "conv1_block2_stage6"
  type: "Convolution"
  bottom: "block1_EltAdd_stage6"
  top: "conv1_block2_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
     type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block2_stage6"
  type: "ReLU"
  bottom: "conv1_block2_stage6"
  top: "conv1_block2_stage6"
}

layer {
  name: "conv2_block2_stage6"
  type: "Convolution"
  bottom: "conv1_block2_stage6"
  top: "conv2_block2_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block2_stage6"
  type: "ReLU"
  bottom: "conv2_block2_stage6"
  top: "conv2_block2_stage6"
}

layer {
  name: "conv3_block2_stage6"
  type: "Convolution"
  bottom: "conv2_block2_stage6"
  top: "conv3_block2_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block2_stage6"
  type: "ReLU"
  bottom: "conv3_block2_stage6"
  top: "conv3_block2_stage6"
}

layer {
  name: "concat_block2_stage6"
  type: "Concat"
  bottom: "conv1_block2_stage6"
  bottom: "conv2_block2_stage6"
  bottom: "conv3_block2_stage6"
  top: "concat_block2_stage6"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block2_stage6"
  type: "Eltwise"
  bottom: "block1_EltAdd_stage6"
  bottom: "concat_block2_stage6"
  top: "block2_EltAdd_stage6"
}

#-------------------block3--------------------
layer {
  name: "conv1_block3_stage6"
  type: "Convolution"
  bottom: "block2_EltAdd_stage6"
  top: "conv1_block3_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block3_stage6"
  type: "ReLU"
  bottom: "conv1_block3_stage6"
  top: "conv1_block3_stage6"
}

layer {
  name: "conv2_block3_stage6"
  type: "Convolution"
  bottom: "conv1_block3_stage6"
  top: "conv2_block3_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block3_stage6"
  type: "ReLU"
  bottom: "conv2_block3_stage6"
  top: "conv2_block3_stage6"
}

layer {
  name: "conv3_block3_stage6"
  type: "Convolution"
  bottom: "conv2_block3_stage6"
  top: "conv3_block3_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block3_stage6"
  type: "ReLU"
  bottom: "conv3_block3_stage6"
  top: "conv3_block3_stage6"
}

layer {
  name: "concat_block3_stage6"
  type: "Concat"
  bottom: "conv1_block3_stage6"
  bottom: "conv2_block3_stage6"
  bottom: "conv3_block3_stage6"
  top: "concat_block3_stage6"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block3_stage6"
  type: "Eltwise"
  bottom: "block2_EltAdd_stage6"
  bottom: "concat_block3_stage6"
  top: "block3_EltAdd_stage6"
}

#---------------------block4----------------------------
layer {
  name: "conv1_block4_stage6"
  type: "Convolution"
  bottom: "block3_EltAdd_stage6"
  top: "conv1_block4_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block4_stage6"
  type: "ReLU"
  bottom: "conv1_block4_stage6"
  top: "conv1_block4_stage6"
}

layer {
  name: "conv2_block4_stage6"
  type: "Convolution"
  bottom: "conv1_block4_stage6"
  top: "conv2_block4_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block4_stage6"
  type: "ReLU"
  bottom: "conv2_block4_stage6"
  top: "conv2_block4_stage6"
}

layer {
  name: "conv3_block4_stage6"
  type: "Convolution"
  bottom: "conv2_block4_stage6"
  top: "conv3_block4_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block4_stage6"
  type: "ReLU"
  bottom: "conv3_block4_stage6"
  top: "conv3_block4_stage6"
}

layer {
  name: "concat_block4_stage6"
  type: "Concat"
  bottom: "conv1_block4_stage6"
  bottom: "conv2_block4_stage6"
  bottom: "conv3_block4_stage6"
  top: "concat_block4_stage6"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block4_stage6"
  type: "Eltwise"
  bottom: "block3_EltAdd_stage6"
  bottom: "concat_block4_stage6"
  top: "block4_EltAdd_stage6"
}

#----------------------block5------------------

layer {
  name: "conv1_block5_stage6"
  type: "Convolution"
  bottom: "block4_EltAdd_stage6"
  top: "conv1_block5_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_block5_stage6"
  type: "ReLU"
  bottom: "conv1_block5_stage6"
  top: "conv1_block5_stage6"
}

layer {
  name: "conv2_block5_stage6"
  type: "Convolution"
  bottom: "conv1_block5_stage6"
  top: "conv2_block5_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_block5_stage6"
  type: "ReLU"
  bottom: "conv2_block5_stage6"
  top: "conv2_block5_stage6"
}

layer {
  name: "conv3_block5_stage6"
  type: "Convolution"
  bottom: "conv2_block5_stage6"
  top: "conv3_block5_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_block5_stage6"
  type: "ReLU"
  bottom: "conv3_block5_stage6"
  top: "conv3_block5_stage6"
}

layer {
  name: "concat_block5_stage6"
  type: "Concat"
  bottom: "conv1_block5_stage6"
  bottom: "conv2_block5_stage6"
  bottom: "conv3_block5_stage6"
  top: "concat_block5_stage6"
  concat_param {
    axis: 1
  }
}

layer {
  name: "bypass_block5_stage6"
  type: "Eltwise"
  bottom: "block4_EltAdd_stage6"
  bottom: "concat_block5_stage6"
  top: "block5_EltAdd_stage6"
}

layer {
  name: "conv1_stage6"
  type: "Convolution"
  bottom: "block5_EltAdd_stage6"
  top: "conv1_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_stage6"
  type: "ReLU"
  bottom: "conv1_stage6"
  top: "conv1_stage6"
}

layer {
  name: "conv2_stage6"
  type: "Convolution"
  bottom: "conv1_stage6"
  top: "conv2_stage6"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 15
    pad: 0
    kernel_size: 1
    weight_filler {
     type: "gaussian"
     std:0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}


